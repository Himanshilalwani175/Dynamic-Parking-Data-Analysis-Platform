# -*- coding: utf-8 -*-
"""Capstone_project_SA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eNNwhwDYP_nQkoMVWAclM9oXDMCF8488

*SUBMITTED BY*- HIMANSHI LALWANI
*email*: hlalwani1705@gmail.com

# Dynamic Pricing for Urban Parking Lots
"""

#PLAN FOR MODEL 1: BASELINE LINEAR MODEL
# Objective
# Create a simple dynamic pricing model that updates the parking price based on occupancy.

#Weâ€™ll use:
#Base price = $10
#Alpha (Î±) = 2

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

df= pd.read_csv('/content/dataset.csv')
df.head()

# Preprocessing
df['timestamp'] = pd.to_datetime(df['LastUpdatedDate'] + ' ' + df['LastUpdatedTime'], format='%d-%m-%Y %H:%M:%S')
df['vehicle_weight'] = df['VehicleType'].map({'car': 1.0, 'bike': 0.5, 'truck': 1.5})
df['traffic_level'] = df['TrafficConditionNearby'].map({'low': 1, 'medium': 2, 'high': 3})

df = df.rename(columns={
    'SystemCodeNumber': 'lot_id',
    'Capacity': 'capacity',
    'Occupancy': 'occupancy',
    'QueueLength': 'queue_length',
    'IsSpecialDay': 'is_special_day',
    'Latitude': 'latitude',
    'Longitude': 'longitude'
})

df_model = df[[
    'lot_id', 'timestamp', 'capacity', 'occupancy', 'queue_length',
    'traffic_level', 'is_special_day', 'vehicle_weight',
    'latitude', 'longitude'
]].sort_values(by=['lot_id', 'timestamp']).reset_index(drop=True)

df.head()

"""**Model- 1**"""

# MODEL 1: Pricing logic
base_price = 10
alpha = 2
df_model['price_model1'] = np.nan

for lot in df_model['lot_id'].unique():
    lot_data = df_model[df_model['lot_id'] == lot].copy()
    prices = [base_price]

    for i in range(1, len(lot_data)):
        prev_price = prices[-1]
        occ = lot_data.iloc[i - 1]['occupancy']
        cap = lot_data.iloc[i - 1]['capacity']
        new_price = prev_price + alpha * (occ / cap)
        new_price = max(5, min(20, new_price))  # Price cap between 5 and 20
        prices.append(new_price)

    df_model.loc[df_model['lot_id'] == lot, 'price_model1'] = prices

# Save or preview
print(df_model[['lot_id', 'timestamp', 'occupancy', 'capacity', 'price_model1']].head())

"""**Model- 2**"""

# Parameters
base_price = 10
alpha = 0.5
beta = 0.3
gamma = 0.2
delta = 0.4
epsilon = 1.0
lambda_ = 1.0

# Calculate raw demand
df_model['raw_demand'] = (
    alpha * (df_model['occupancy'] / df_model['capacity']) +
    beta * df_model['queue_length'] -
    gamma * df_model['traffic_level'] +
    delta * df_model['is_special_day'] +
    epsilon * df_model['vehicle_weight']
)

# Normalize demand
min_d = df_model['raw_demand'].min()
max_d = df_model['raw_demand'].max()
df_model['norm_demand'] = (df_model['raw_demand'] - min_d) / (max_d - min_d)

# Compute price
df_model['price_model2'] = base_price * (1 + lambda_ * df_model['norm_demand'])

# Clip to smooth range
df_model['price_model2'] = df_model['price_model2'].clip(lower=5, upper=20)

print(df_model[['timestamp', 'lot_id', 'price_model2']].head())

"""**Model-3**"""

from math import radians, sin, cos, sqrt, atan2
import numpy as np

def haversine(lat1, lon1, lat2, lon2):
    R = 6371  # Earth radius in km
    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
    dlat, dlon = lat2 - lat1, lon2 - lon1
    a = sin(dlat/2)**2 + cos(lat1)*cos(lat2)*sin(dlon/2)**2
    return R * 2 * atan2(sqrt(a), sqrt(1 - a))

# Create a distance lookup between lots
unique_lots = df_model[['lot_id', 'latitude', 'longitude']].drop_duplicates()
lot_coords = dict(zip(unique_lots['lot_id'], zip(unique_lots['latitude'], unique_lots['longitude'])))

# Model 3 pricing
df_model['price_model3'] = df_model['price_model2']  # Start with Model 2 price

# Group by timestamp for dynamic competition simulation
for ts in df_model['timestamp'].unique():
    current_time_df = df_model[df_model['timestamp'] == ts]

    for i, row in current_time_df.iterrows():
        this_lot = row['lot_id']
        this_price = row['price_model2']
        this_occ = row['occupancy']
        this_cap = row['capacity']
        this_lat, this_lon = lot_coords[this_lot]

        nearby_prices = []

        for other_lot in unique_lots['lot_id']:
            if other_lot != this_lot:
                olat, olon = lot_coords[other_lot]
                distance = haversine(this_lat, this_lon, olat, olon)
                if distance <= 1.0:
                    comp_price = current_time_df[current_time_df['lot_id'] == other_lot]['price_model2']
                    if not comp_price.empty:
                        nearby_prices.append(comp_price.values[0])

        if nearby_prices:
            avg_comp_price = np.mean(nearby_prices)
            # if full and competitors cheaper â†’ lower price
            if this_occ >= this_cap and this_price > avg_comp_price:
                adjusted = max(5, avg_comp_price - 0.5)
            # if competitors expensive â†’ raise price
            elif this_price < avg_comp_price:
                adjusted = min(20, this_price + 0.5)
            else:
                adjusted = this_price
            df_model.loc[i, 'price_model3'] = adjusted

print(df_model[['timestamp', 'lot_id', 'price_model3']].head())

"""**Final Pathway Code for Model 3**"""

!pip install pathway bokeh --quiet

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import datetime
from datetime import datetime
import pathway as pw
import bokeh.plotting
import panel as pn

import pathway as pw
import numpy as np
from math import radians, sin, cos, sqrt, atan2

# ----------- 1. Define Input Schema -----------
class ParkingInput(pw.Schema):
    lot_id: str
    timestamp: str
    latitude: float
    longitude: float
    occupancy: float
    capacity: float
    queue_length: float
    traffic_level: float
    is_special_day: int
    vehicle_weight: float

# ----------- 2. Define Output Schema -----------
class ParkingOutput(pw.Schema):
    lot_id: str
    timestamp: str
    price: float

# ----------- 3. Haversine Function -----------
def haversine(lat1, lon1, lat2, lon2):
    R = 6371
    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
    dlat, dlon = lat2 - lat1, lon2 - lon1
    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2
    return R * 2 * atan2(sqrt(a), sqrt(1 - a))

# ----------- 4. Pricing UDF -----------
@pw.udf
def compute_price(
    lot_id, occupancy, capacity, queue_length, traffic_level,
    is_special_day, vehicle_weight, latitude, longitude,
    all_lot_ids, all_lats, all_lons, all_prices
):
    # Model 2 base demand formula
    base_price = 10
    Î±, Î², Î³, Î´, Îµ, Î» = 0.5, 0.3, 0.2, 0.4, 1.0, 1.0
    radius_km = 1.0

    demand = (
        Î± * (occupancy / capacity)
        + Î² * queue_length
        - Î³ * traffic_level
        + Î´ * is_special_day
        + Îµ * vehicle_weight
    )

    norm_demand = (demand - 1) / (6 - 1)
    price = base_price * (1 + Î» * norm_demand)

    # Nearby competitor price check
    nearby_prices = []
    for comp_id, lat2, lon2, comp_price in zip(all_lot_ids, all_lats, all_lons, all_prices):
        if comp_id != lot_id:
            dist = haversine(latitude, longitude, lat2, lon2)
            if dist <= radius_km:
                nearby_prices.append(comp_price)

    if nearby_prices:
        avg = np.mean(nearby_prices)
        if occupancy >= capacity and price > avg:
            price = max(5, avg - 0.5)
        elif price < avg:
            price = min(20, price + 0.5)

    return round(price, 2)

# ----------- 5. Read the Stream -----------
stream = pw.io.csv.read(
    "parking_stream.csv",
    schema=ParkingInput,
    mode="streaming",
    autocommit_duration_ms=1000
)

# ----------- 6. Snapshot for Cross Join (Competition Logic) -----------
price_snapshot = stream.select(
    lot_id=pw.this.lot_id,
    latitude=pw.this.latitude,
    longitude=pw.this.longitude,
    price=pw.this.occupancy * 0 + 10  # dummy initial
)

joined = stream + price_snapshot

# ----------- 7. Apply Model 3 Pricing Logic -----------
priced_stream = joined.select(
    lot_id=pw.left.lot_id,
    timestamp=pw.left.timestamp,
    price=compute_price(
        pw.left.lot_id,
        pw.left.occupancy,
        pw.left.capacity,
        pw.left.queue_length,
        pw.left.traffic_level,
        pw.left.is_special_day,
        pw.left.vehicle_weight,
        pw.left.latitude,
        pw.left.longitude,
        pw.right.lot_id,
        pw.right.latitude,
        pw.right.longitude,
        pw.right.price
    )
)

# ----------- 8. Write to Output CSV -----------
pw.io.csv.write(priced_stream, "output_prices/", schema=ParkingOutput)

# ----------- 9. Run the Pipeline -----------
pw.run()

from math import radians, sin, cos, sqrt, atan2

# ---------- 1. Define Schema ----------
class ParkingInput(pw.Schema):
    lot_id: str
    timestamp: str
    latitude: float
    longitude: float
    occupancy: float
    capacity: float
    queue_length: float
    traffic_level: float
    is_special_day: int
    vehicle_weight: float

class ParkingOutput(pw.Schema):
    lot_id: str
    timestamp: str
    price: float

# ---------- 2. Haversine Function ----------
def haversine(lat1, lon1, lat2, lon2):
    R = 6371
    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
    dlat, dlon = lat2 - lat1, lon2 - lon1
    a = sin(dlat/2)**2 + cos(lat1)*cos(lat2)*sin(dlon/2)**2
    return R * 2 * atan2(sqrt(a), sqrt(1 - a))

# ---------- 3. UDF Pricing Logic ----------
@pw.udf
def compute_competitive_price(lot_id, occupancy, capacity, queue, traffic, special, v_weight,
                               lat, lon,
                               comp_ids, comp_lats, comp_lons, comp_prices):

    # Model 2 demand
    base_price = 10
    alpha, beta, gamma, delta, epsilon, lambda_ = 0.5, 0.3, 0.2, 0.4, 1.0, 1.0
    radius_km = 1.0

    demand = (
        alpha * (occupancy / capacity) +
        beta * queue -
        gamma * traffic +
        delta * special +
        epsilon * v_weight
    )
    # Ensure norm_demand calculation handles potential division by zero if max_d equals min_d
    min_d = -0.7  # Using estimated min demand from previous model
    max_d = 5.75 # Using estimated max demand from previous model
    norm_demand = (demand - min_d) / (max_d - min_d) if max_d != min_d else 0.0


    price = base_price * (1 + lambda_ * norm_demand)

    # Competitor price influence
    nearby_prices = []
    for cid, clat, clon, cprice in zip(comp_ids, comp_lats, comp_lons, comp_prices):
        if cid != lot_id and haversine(lat, lon, clat, clon) <= radius_km:
            nearby_prices.append(cprice)

    if nearby_prices:
        avg_price = np.mean(nearby_prices)
        # if full and competitors cheaper -> lower price
        if occupancy >= capacity and price > avg_price:
            adjusted = max(5, avg_price - 0.5)
        # if competitors expensive -> raise price
        elif price < avg_price:
            adjusted = min(20, price + 0.5)
        else:
            adjusted = price
        return round(adjusted, 2)

    return round(price, 2)

# ---------- 4. Stream Input ----------
# Create a parking_stream.csv file with a subset of the data for testing
df_model.head(1000).to_csv("parking_stream.csv", index=False)

stream = pw.io.csv.read(
    "parking_stream.csv",
    schema=ParkingInput,
    mode="streaming",
    autocommit_duration_ms=1000
)

import os
import shutil

# ---------- 5. Cross Join for Competition ----------
# Add dummy key for cross join to both tables
stream_with_key = stream.select(
    stream.lot_id,
    stream.timestamp,
    stream.latitude,
    stream.longitude,
    stream.occupancy,
    stream.capacity,
    stream.queue_length,
    stream.traffic_level,
    stream.is_special_day,
    stream.vehicle_weight,
    key=1
)
snapshot_with_key = stream.select(
    comp_lot_id=pw.this.lot_id,
    comp_latitude=pw.this.latitude,
    comp_longitude=pw.this.longitude,
    comp_price=pw.this.occupancy * 0 + 10,  # initial dummy price
    key=1
)

# Perform a cross join using the dummy key
joined = stream_with_key.join(snapshot_with_key, pw.left.key == pw.right.key)

# ---------- 6. Apply Pricing Logic ----------
priced = joined.select(
    lot_id=joined.lot_id,
    timestamp=joined.timestamp,
    price=compute_competitive_price(
        joined.lot_id,
        joined.occupancy,
        joined.capacity,
        joined.queue_length,
        joined.traffic_level,
        joined.is_special_day,
        joined.vehicle_weight,
        joined.latitude,
        joined.longitude,
        joined.comp_lot_id,
        joined.comp_latitude,
        joined.comp_longitude,
        joined.comp_price
    )
)

# ---------- 7. Write Output ----------
# Remove the output directory if it exists
if os.path.exists("output_prices/"):
    shutil.rmtree("output_prices/")
os.makedirs("output_prices/", exist_ok=True) # Ensure directory exists

pw.io.csv.write(priced, "output_prices.csv")

import os
import shutil

# Clean both .csv and folder with the same name
if os.path.exists("output_prices.csv"):
    os.remove("output_prices.csv")
if os.path.exists("output_prices"):
    shutil.rmtree("output_prices", ignore_errors=True)

# âœ… Write to a CSV file (no schema, no header, no mode)
pw.io.csv.write(priced_stream, "output_prices.csv")

# Run the pipeline
pw.run()

import os
import shutil

for name in ["output_prices", "output_prices.csv", "pathway_output.csv"]:
    if os.path.exists(name):
        if os.path.isdir(name):
            shutil.rmtree(name)
        else:
            os.remove(name)

import pathway as pw

# Define your output stream...
# (Assume 'priced_stream' is already created properly above this)

# Clean any conflicting files or folders
import os
import shutil
for name in ["output_prices", "output_prices.csv", "pathway_output.csv"]:
    if os.path.exists(name):
        if os.path.isdir(name):
            shutil.rmtree(name)
        else:
            os.remove(name)

# âœ… Write to a clean, never-used filename
pw.io.csv.write(priced_stream, "pathway_output.csv")
pw.run()

final_pricing_output= df_model[['lot_id', 'price_model1', 'price_model2', 'price_model3' ]]

final_pricing_output.head()

"""**Bokeh Dashboard Code**"""

from bokeh.plotting import figure, curdoc
from bokeh.models import ColumnDataSource, Select
from bokeh.layouts import column
import pandas as pd
import os
from glob import glob

# ---------- PARAMETERS ----------
POLL_INTERVAL = 2000  # in milliseconds
OUTPUT_FOLDER = "output_prices"

# ---------- Load Latest CSV from Output ----------
def load_latest_data():
    csv_files = sorted(glob(os.path.join(OUTPUT_FOLDER, "*.csv")), reverse=True)
    if not csv_files:
        return pd.DataFrame(columns=["lot_id", "timestamp", "price"])

    df = pd.read_csv(csv_files[0])
    if 'timestamp' in df.columns:
        df['timestamp'] = pd.to_datetime(df['timestamp'])
    return df

# Initial data
df = load_latest_data()
lot_ids = df['lot_id'].unique().tolist() if not df.empty else ["Unknown"]
initial_lot = lot_ids[0] if lot_ids else "Unknown"

# ---------- ColumnDataSource ----------
source = ColumnDataSource(data=dict(x=[], y=[]))

# ---------- Plot ----------
p = figure(x_axis_type='datetime', title=f"Live Pricing - Lot: {initial_lot}",
           width=900, height=400)
p.line(x='x', y='y', source=source, line_width=2, color="green", legend_label="Dynamic Price")

p.xaxis.axis_label = "Time"
p.yaxis.axis_label = "Price ($)"
p.legend.location = "top_left"

# ---------- Dropdown ----------
dropdown = Select(title="Select Parking Lot", value=initial_lot, options=lot_ids)

# ---------- Update Function ----------
def update():
    df = load_latest_data()
    if df.empty:
        return

    selected_lot = dropdown.value
    df_lot = df[df['lot_id'] == selected_lot]

    if not df_lot.empty:
        df_lot = df_lot.sort_values(by="timestamp")
        source.data = {
            "x": df_lot["timestamp"],
            "y": df_lot["price"]
        }
        p.title.text = f"Live Pricing - Lot: {selected_lot}"

# ---------- Dropdown Callback ----------
def on_lot_change(attr, old, new):
    update()

dropdown.on_change("value", on_lot_change)

# ---------- Layout ----------
curdoc().add_root(column(dropdown, p))
curdoc().add_periodic_callback(update, POLL_INTERVAL)

import panel as pn
from bokeh.plotting import curdoc
from bokeh.layouts import column
from IPython.display import display, HTML

pn.extension()

# Assuming you already have dropdown and p (your Bokeh plot)
# The layout is already added to curdoc() in the previous cell

# To run the server and display the dashboard in the output of this cell:
# This will serve the application and allow the Python callbacks to function.
# Note: Running panel.serve() will block the execution of subsequent cells
# You might need to run this cell in a separate thread or process if you want to execute other cells

curdoc().add_root(column(dropdown, p))
pn.serve(curdoc(), notebook_url='localhost:8888') # Use curdoc() directly with pn.serve

# Install ngrok
!pip install pyngrok --quiet

# Run ngrok to expose the port. Replace <PORT_NUMBER> with the actual port from the panel.serve output.
from pyngrok import ngrok
import threading
import time

# Find the port number from the panel.serve output
# In the previous cell's output, look for something like "Launching server at http://localhost:<PORT_NUMBER>"
# Replace <PORT_NUMBER> with that number.
PORT_NUMBER = 46409 # Replace with the actual port number

# Terminate any existing ngrok tunnels
ngrok.kill()

# Open a new ngrok tunnel
public_url = ngrok.connect(PORT_NUMBER).public_url
print(f"ngrok tunnel stable at: {public_url}")

# Keep the cell alive to maintain the tunnel and panel server
try:
    while True:
        time.sleep(1)
except KeyboardInterrupt:
    print("Tunnel stopped.")
    ngrok.kill()

"""To use your ngrok authtoken, first add it to Colab's Secrets. Click the "ðŸ”‘" icon in the left sidebar, add a new secret named `NGROK_AUTH_TOKEN`, and paste your authtoken as the value. Make sure "Notebook access" is enabled. Then run the following cell to load the authtoken."""

from google.colab import userdata
import pyngrok

# Load the ngrok authtoken from Colab secrets
NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')

# Set the ngrok authtoken for pyngrok
pyngrok.conf.get_default().auth_token = NGROK_AUTH_TOKEN

print("ngrok authtoken set.")

from bokeh.plotting import figure, curdoc
from bokeh.models import ColumnDataSource, Select
from bokeh.layouts import column
import pandas as pd
import os
from glob import glob

# CONFIG
DATA_FILE = "pathway_output.csv"  # Replace with your output file
REFRESH_INTERVAL_MS = 2000

# Initial load
if os.path.exists(DATA_FILE):
    df = pd.read_csv(DATA_FILE)
    df["timestamp"] = pd.to_datetime(df["timestamp"])
else:
    df = pd.DataFrame(columns=["lot_id", "timestamp", "price"])

lot_ids = df["lot_id"].unique().tolist() if not df.empty else ["Unknown"]
default_lot = lot_ids[0] if lot_ids else "Unknown"

# Data source
source = ColumnDataSource(data=dict(x=[], y=[]))

# Bokeh figure
p = figure(x_axis_type="datetime", width=900, height=400, title=f"Live Dynamic Pricing: Lot {default_lot}")
p.line(x="x", y="y", source=source, line_width=2, color="blue")
p.xaxis.axis_label = "Time"
p.yaxis.axis_label = "Price ($)"

# Dropdown for lot_id
dropdown = Select(title="Select Parking Lot", value=default_lot, options=lot_ids)

# Update function
def update():
    if not os.path.exists(DATA_FILE):
        return

    df = pd.read_csv(DATA_FILE)
    df["timestamp"] = pd.to_datetime(df["timestamp"])
    selected_lot = dropdown.value

    df_lot = df[df["lot_id"] == selected_lot]
    df_lot = df_lot.sort_values("timestamp")

    source.data = {
        "x": df_lot["timestamp"],
        "y": df_lot["price"]
    }

    p.title.text = f"Live Dynamic Pricing: Lot {selected_lot}"

# Callback on dropdown change
def dropdown_callback(attr, old, new):
    update()

dropdown.on_change("value", dropdown_callback)

# Layout and server
layout = column(dropdown, p)
curdoc().add_root(layout)
curdoc().add_periodic_callback(update, REFRESH_INTERVAL_MS)

